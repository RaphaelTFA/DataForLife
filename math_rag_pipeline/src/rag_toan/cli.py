import typer
from pathlib import Path
import uuid
from math_rag_pipeline.src.rag_toan.ingestion.pdf_loader import save_extracted_text
from math_rag_pipeline.src.rag_toan.ingestion.text_cleaner import clean_text
from math_rag_pipeline.src.rag_toan.chunking.splitter import split_by_headings, chunk_by_words
from math_rag_pipeline.src.rag_toan.embedding.embedder import Embedder
from math_rag_pipeline.src.rag_toan.indexer.chroma_index import ChromaIndex
from math_rag_pipeline.src.rag_toan.retriever.retriever import Retriever
from math_rag_pipeline.src.rag_toan.llm.client import ask_llm
from math_rag_pipeline.src.rag_toan.config import EXTRACTED_DIR, CHUNKS_DIR
from math_rag_pipeline.src.rag_toan.utils.io import write_text_file, append_jsonl, read_text_file
from math_rag_pipeline.src.rag_toan.qg.concept_tagger import tag_concept
from math_rag_pipeline.src.rag_toan.qg.qa_pair_generator import generate_qa_pairs
from math_rag_pipeline.src.rag_toan.qg.evaluator import evaluate_question
import sys

app = typer.Typer(help="RAG To√°n ‚Äî CLI: ingest / index / query")

@app.command()
def ingest(pdf_path: str, out_name: str = None):
    """
    Extract + clean text from PDF and save to data/extracted.
    """
    typer.echo("üîé Extracting PDF ...")
    extracted_path = save_extracted_text(pdf_path, out_basename=out_name)
    typer.echo(f"‚úÖ Extracted saved: {extracted_path}")

    typer.echo("üßº Cleaning text ...")
    raw = read_text_file(extracted_path)
    cleaned = clean_text(raw)
    cleaned_path = Path(extracted_path).with_name(Path(extracted_path).stem + ".clean.txt")
    write_text_file(str(cleaned_path), cleaned)
    typer.echo(f"‚úÖ Cleaned saved: {cleaned_path}")

@app.command()
def index(chunk_size: int = 400, overlap: int = 50, embed_model: str = None):
    """
    Chunk -> embed -> index into Chroma. Uses latest cleaned file in data/extracted.
    """
    files = sorted(Path(EXTRACTED_DIR).glob("*.clean.txt"))
    if not files:
        typer.echo("Kh√¥ng t√¨m th·∫•y file cleaned trong data/extracted. Ch·∫°y `ingest` tr∆∞·ªõc.")
        raise typer.Exit(code=1)
    latest = files[-1]
    text = read_text_file(str(latest))
    typer.echo(f"üìÑ Chunking {latest.name} ...")
    chunks = split_by_headings(text, chunk_size=chunk_size, overlap=overlap)
    if not chunks:
        typer.echo("Kh√¥ng c√≥ chunk n√†o ƒë∆∞·ª£c t·∫°o ‚Äî ki·ªÉm tra file.")
        raise typer.Exit(code=1)
    typer.echo(f"‚û°Ô∏è {len(chunks)} chunks created.")

    typer.echo("üì• Generating embeddings ...")
    embedder = Embedder(model_name=embed_model) if embed_model else Embedder()
    embeddings = embedder.encode(chunks)

    ids = [str(uuid.uuid4()) for _ in chunks]
    metadatas = [{"source": latest.name, "chunk_index": i} for i in range(len(chunks))]

    typer.echo("üíæ Writing to Chroma DB ...")
    index = ChromaIndex()
    index.add(ids=ids, texts=chunks, embeddings=embeddings, metadatas=metadatas)
    index.persist()

    out_chunks = Path(CHUNKS_DIR) / (latest.stem + ".chunks.jsonl")
    for _id, chunk, md in zip(ids, chunks, metadatas):
        append_jsonl(str(out_chunks), {"id": _id, "text": chunk, "metadata": md})
    typer.echo(f"‚úÖ Indexed and saved chunk metadata to {out_chunks}")

@app.command()
def query(q: str, top_k: int = 3):
    """
    Retrieve top_k relevant chunks and ask LLM to answer.
    """
    retriever = Retriever()
    typer.echo("üîé Retrieving relevant chunks ...")
    docs = retriever.retrieve(q, top_k=top_k)
    if not docs:
        typer.echo("Kh√¥ng c√≥ t√†i li·ªáu ph√π h·ª£p trong index.")
        raise typer.Exit(code=1)
    context = "\n\n---\n\n".join([d["text"] for d in docs])
    typer.echo(f"üß† Sending {len(docs)} chunks to LLM ...")
    answer = ask_llm(context, q)
    typer.echo("\n===== LLM ANSWER =====\n")
    typer.echo(answer)
    typer.echo("\n======================\n")

app = typer.Typer(help="üìò Math Generator CLI")

qg_app = typer.Typer(help="üéì Question Generation pipeline")
app.add_typer(qg_app, name="qg")

@qg_app.command("run")
def run_qg(input_file: str, out_file: str = "data/generated_questions.jsonl", num: int = 5):
    """
    Ch·∫°y to√†n b·ªô pipeline sinh c√¢u h·ªèi to√°n h·ªçc t·ª´ 1 file ƒë√£ extract/clean.
    """
    text = read_text_file(input_file)
    typer.echo("üîç X√°c ƒë·ªãnh ch·ªß ƒë·ªÅ ...")
    concept = tag_concept(text)
    typer.echo(f"üìò Ch·ªß ƒë·ªÅ: {concept}")

    typer.echo("üß† Sinh c√¢u h·ªèi & ƒë√°p √°n ...")
    qa_pairs = generate_qa_pairs(text, concept, num=num)

    typer.echo("‚úÖ ƒê√°nh gi√° c√¢u h·ªèi ...")
    for qa in qa_pairs:
        qa["evaluation"] = evaluate_question(qa["question"], qa.get("answer", ""))
        append_jsonl(out_file, qa)

    typer.echo(f"‚úÖ Ho√†n th√†nh! L∆∞u {len(qa_pairs)} c√¢u h·ªèi v√†o {out_file}")

@app.command()
def generate(
    subject: str = typer.Option(
        ..., 
        help="Ch·ªß ƒë·ªÅ to√°n h·ªçc (algebra, geometry, calculus, statistics, trigonometry)"
    ),
    difficulty: str = typer.Option(
        ..., 
        help="ƒê·ªô kh√≥ (easy, medium, hard, challenging)"
    ),
    education_level: str = typer.Option(
        "high_school", 
        help="C·∫•p ƒë·ªô gi√°o d·ª•c (elementary, middle_school, high_school, university)"
    ),
    num: int = typer.Option(
        5, 
        help="S·ªë l∆∞·ª£ng c·∫∑p c√¢u h·ªèi-ƒë√°p √°n c·∫ßn t·∫°o"
    ),
    use_rag: bool = typer.Option(
        True, 
        help="S·ª≠ d·ª•ng RAG ƒë·ªÉ t√¨m ng·ªØ c·∫£nh li√™n quan"
    )
):
    """
    Sinh c√¢u h·ªèi v√† ƒë√°p √°n d·ª±a v√†o ch·ªß ƒë·ªÅ v√† ƒë·ªô kh√≥.
    """
    from math_rag_pipeline.src.rag_toan.qg.qa_pair_generator import generate_qa_pairs as gen_qa, save_qa_pairs

    typer.echo(f"üß† ƒêang sinh {num} c√¢u h·ªèi {subject} v·ªõi ƒë·ªô kh√≥ {difficulty} cho {education_level}...")
    
    try:
        qa_pairs = gen_qa(
            subject=subject,
            difficulty=difficulty,
            education_level=education_level,
            num=num,
            use_rag=use_rag
        )
        
        # Save the generated QA pairs
        output_path = save_qa_pairs(
            qa_pairs=qa_pairs,
            subject=subject,
            difficulty=difficulty,
            education_level=education_level
        )
        
        # Display results
        typer.echo("\n===== GENERATED QUESTIONS =====\n")
        for i, qa in enumerate(qa_pairs, 1):
            typer.echo(f"[{i}] Question: {qa['question']}")
            typer.echo(f"    Answer: {qa['answer'][:100]}..." if len(qa['answer']) > 100 else f"    Answer: {qa['answer']}")
            typer.echo("")
        
        typer.echo(f"\n‚úÖ Generated {len(qa_pairs)} QA pairs and saved to: {output_path}")
        
    except ValueError as e:
        typer.echo(f"‚ùå Error: {str(e)}")
        typer.echo("\nAvailable options:")
        typer.echo("- subjects: algebra, geometry, calculus, statistics, trigonometry")
        typer.echo("- difficulty: easy, medium, hard, challenging")
        typer.echo("- education_level: elementary, middle_school, high_school, university")
        raise typer.Exit(code=1)
    except Exception as e:
        typer.echo(f"‚ùå Error generating questions: {str(e)}")
        raise typer.Exit(code=1)


if __name__ == "__main__":
    app()
